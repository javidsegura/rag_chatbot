a = " ViT, or Vision Transformer, has shown promising results in various recognition benchmarks at a lower pre-training cost. It has been tested on datasets like ImageNet, ImageNet-21k, and JFT, transferring models to tasks such as ImageNet, CIFAR-10/100, Oxford-IIIT Pets, and Oxford Flowers-102. While ViT performs well on larger datasets, it tends to overfit more than ResNets on smaller datasets. The results suggest that ViT is beneficial for learning relevant patterns directly from data on larger datasets. Additionally, there is ongoing research on applying ViT to other computer vision tasks like detection and segmentation, as well as exploring self-supervised pre-training methods to bridge the gap between self-supervised and large-scale supervised pre-training. Further scaling of ViT is expected to lead to improved performance in the future."

print(len(a))