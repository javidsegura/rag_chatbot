
# ALL THE CONFIGURATIONS IS FURTHER EXPLAIN IN 'load.configuration.py'

directories:
  data_directory: data/docs
  data_directory_2: data/docs_2
  persist_directory: /Users/javierdominguezsegura/Programming/Python/Side projects/RAG 4/data/vectordb/processed/chroma/ # Create db w/ this path
  custom_persist_directory: /Users/javierdominguezsegura/Programming/Python/Side projects/RAG 4/data/vectordb/uploaded/chroma/ #If existent this will be the path

embedding_model_config:
  model: "text-embedding-ada-002" # Is there not one that is more powerful?

llm_config:
    llm_template: "You are a chatbot. You'll receive a prompt that includes a chat history, retrieved content from the vectorDB based on the user's question, and the source.\ 
    Your task is to respond to the user's new question using the information from the vectorDB without relying on your own knowledge. Give a response of 150-175 words.\
    you will receive a prompt with the the following format:

    # Chat history:\n
    [user query, response]\n\n

    # Retrieved content number:\n
    Content\n\n
    Source\n\n

    # User question:\n
    New question
    "
    model: "gpt-3.5-turbo"
    temperature: 0.0
    max_token: 4096

summarizer_config:
    max_final_token: 3000
    character_overlap: 100
    token_threshold: 0
    summarizer_llm_template: "You are an expert text summarizer. You will receive a text and your task is to summarize and keep all the key information.\
      Kepp the maximum length of summary wihin {} number of tokens."
    final_summarizer_llm_template: "You are an expert text summarizer. You will receive a text and your task is to give a comprehensive summary and keep all the key information."


splitter_config:
  chunk_size: 1500
  chunk_overlap: 100

retrieval_config:
  k: 3

serve:
  port: 8000

memory:
  number_of_q_a_pairs: 4


  
